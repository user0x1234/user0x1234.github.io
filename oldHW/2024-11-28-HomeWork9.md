---
layout: post
title: "HomeWork 9"
date: 2024-11-28
markdown: kramdown
---

## Research Topics: Theory (T)

- **T1**: Mention the main properties of the sampling mean and variance.
Illustrate the law of large numbers and some possible applications, especially related to cybersecurity concepts.


- **A1**: Application / practice
Following the same scheme of HMWK 7 compute the distribution of the sampling variance ("corrected" or not).
Determine the distribution of the variances of the samples, and its mean and variance.
discussing the observed relationship with the mean and variance of the parent (theoretical) distribution. 


# <span style="color:red">Researches about Theory (T)</span>


# Sampling Mean and Variance: Key Concepts and Applications

## Main Properties of the Sampling Mean

1. **Unbiasedness**:  
   - The expected value of the sample mean $\( \bar{X} \)$ is equal to the population mean $\( \mu \)$:
     $$
     \mathbb{E}[\bar{X}] = \mu
     $$

2. **Reduced Variability with Larger Samples**:  
   - The variance of the sample mean decreases as the sample size \( n \) increases:
     $$
     \text{Var}(\bar{X}) = \frac{\sigma^2}{n}
     $$
     where $\( \sigma^2 \)$ is the population variance.

3. **Central Limit Theorem (CLT)**:  
   - For large $\( n \)$, the sampling distribution of $\( \bar{X} \)$ approaches a normal distribution, regardless of the population's distribution.

---

## Main Properties of the Sampling Variance

1. **Unbiased Estimator**:  
   - The sample variance $\( s^2 \)$ is an unbiased estimate of the population variance $\( \sigma^2 \)$:
     
     $$
     s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
     $$

2. **Dependence on Sample Size**:  
   - As the sample size $\( n \)$ increases, the sample variance becomes a more stable and accurate estimate of the population variance.

3. **Stochastic Nature**:  
   - While $\( s^2 \)$ estimates $\( \sigma^2 \)$, it varies from sample to sample.

---

## Law of Large Numbers (LLN)

The **Law of Large Numbers (LLN)** ensures that as the sample size $\( n \)$ increases, the sample mean $\( \bar{X} \)$ converges to the population mean $\( \mu \)$. This is formalized as:
$$
\lim_{n \to \infty} \bar{X}_n = \mu
$$

### Key Insights:
- The LLN highlights the reliability of large samples in approximating population parameters.
- Variability in estimates decreases with larger $\( n \)$.

---

## Applications of LLN in Cybersecurity

1. **Anomaly Detection**:  
   - Monitoring login attempts or network packet sizes to detect deviations from the norm.  
   - For instance, analyzing the mean response time for successful logins can reveal potential brute-force attacks.

2. **Risk Assessment**:  
   - Estimating average probabilities of attack vectors based on historical data.  
   - Larger datasets improve accuracy in calculating these probabilities.

3. **Performance Monitoring**:  
   - Assessing average system performance metrics like throughput, downtime, or detection times.  
   - Large samples ensure stable benchmarks for performance evaluation.

4. **Authentication Systems**:  
   - Computing average failure rates in multi-factor authentication systems to identify potential attack patterns.

---

## Practical Example

### Scenario:
- **Dataset**: Response times for detecting phishing attempts.
- **Population Parameters**: Mean $\( \mu = 25 \)$ seconds, variance $\( \sigma^2 = 16 \)$.

### Simulation:
1. Collect samples of size $\( n = 10, 50, 100, 1000 \)$.
2. Compute the sample mean $\( \bar{X} \)$ for each sample.
3. Observe how $\( \bar{X} \)$ approaches $\( \mu = 25 \)$ as $\( n \)$ increases.

### Visualization:
- Plot $\( \bar{X} \)$ against $\( n \)$ to show convergence.
- Highlight reduced variability in sample mean for larger $\( n \)$.

---

## Key Takeaway
The Law of Large Numbers and properties of sampling mean and variance are foundational in cybersecurity. They allow for robust predictions, anomaly detection, and system performance evaluations, ensuring more reliable and secure operations in the face of uncertainty.


# <span style="color:red">Researches about Application (A)</span>

# Sampling Variance Analysis

## Objective:
1. Compute the distribution of the sampling variance (corrected and uncorrected).
2. Determine:
   - The mean and variance of the sampling variances.
3. Compare the results with the population (theoretical) variance $\( \sigma^2 \)$ and discuss observed relationships.

---

## Theoretical Background:

### Population Variance:
The variance of a population is defined as:
$$
\sigma^2 = \mathbb{E}[(X - \mu)^2]
$$

### Sample Variance:
The sample variance can be computed using two formulas:
1. **Uncorrected Sample Variance**:
   $$
   s_u^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2
   $$
   This underestimates the population variance for finite \( n \).

2. **Corrected Sample Variance** (Bessel's correction):
   $$
   s_c^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
   $$
   The cor$rection makes $\( s_c^2 \)$ an unbiased estimator of $\( \sigma^2 \)$.

---

## Sampling Variance Distribution:
The sampling variance follows a scaled chi-squared distribution:
$$
(n-1)s_c^2 \sim \sigma^2 \chi^2_{n-1}
$$
This means:
- The mean of $\( s_c^2 \)$ equals the population variance:
  $$
  \mathbb{E}[s_c^2] = \sigma^2
  $$
- The variance of $\( s_c^2 \)$ depends on $\( n \)$:
  $$
  \text{Var}(s_c^2) = \frac{2\sigma^4}{n-1}
  $$

---

## Practical Implementation:

### Steps:
1. Generate a large number $\( m \)$ of samples, each of size $\( n \)$, from a given parent distribution.
2. For each sample, compute:
   - The corrected sample variance $\( s_c^2 \)$.
   - The uncorrected sample variance $\( s_u^2 \)$.
3. Collect the variances across samples and plot their distributions.
4. Compute:
   - The mean and variance of the distributions of $\( s_c^2 \)$ and $\( s_u^2 \)$.
5. Compare these results with the theoretical variance $\( \sigma^2 \)$ of the parent distribution.

### Observations:
1. The mean of $\( s_c^2 \)$ should converge to $\( \sigma^2 \)$.
2. The variance of $\( s_c^2 \)$ should decrease as $\( n \)$ increases.
3. The uncorrected variance $\( s_u^2 \)$ is biased and underestimates $\( \sigma^2 \)$.

---

## Example Implementation:

### **Simulation Parameters**:
- Parent distribution: Normal ($\( \mu = 0, \sigma^2 = 1 \)$).
- Number of samples ($\( m \)$): 1000.
- Sample sizes (\( n \)): 10, 30, 50, 100.

### **Simulation Results**:
1. **Distributions**:
   - Plot histograms of $\( s_c^2 \)$ and $\( s_u^2 \)$ for each $\( n \)$.
2. **Summary Statistics**:
   - Compare the theoretical variance $\( \sigma^2 \)$ with the mean of $\( s_c^2 \)$ and $\( s_u^2 \)$.
   - Analyze the variance of $\( s_c^2 \)$ and compare with $\( \frac{2\sigma^4}{n-1} \)$.

---



<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sampling Variance with Plot</title>
    <style>
        canvas {
            background-color: #fff;
            border: 1px solid #ccc;
        }
    </style>
</head>
<body>
    <h1>Sampling Variance Simulation</h1>
    <div>
        <label>Number of Samples (m): <input type="number" id="numSamples" value="1000"></label><br>
        <label>Sample Size (n): <input type="number" id="sampleSize" value="30"></label><br>
        <button onclick="simulate()">Run Simulation</button>
    </div>
    <canvas id="variancePlot" width="800" height="400"></canvas>
    <pre id="results"></pre>

    <script>
        function generateUniformSample(a, b, size) {
            const sample = [];
            for (let i = 0; i < size; i++) {
                sample.push(a + Math.random() * (b - a));
            }
            return sample;
        }

        function calculateVariance(sample, corrected = true) {
            const n = sample.length;
            const mean = sample.reduce((sum, x) => sum + x, 0) / n;
            const variance = sample.reduce((sum, x) => sum + Math.pow(x - mean, 2), 0);
            return corrected ? variance / (n - 1) : variance / n;
        }

        function drawPlot(context, data, color, label) {
            const width = context.canvas.width;
            const height = context.canvas.height;
            const padding = 50;

            const maxData = Math.max(...data);
            const scale = (height - 2 * padding) / maxData;

            context.clearRect(0, 0, width, height);

            // Draw axes
            context.beginPath();
            context.moveTo(padding, padding);
            context.lineTo(padding, height - padding);
            context.lineTo(width - padding, height - padding);
            context.strokeStyle = "#000";
            context.stroke();

            // Draw labels for axes
            context.font = "14px Arial";
            context.fillStyle = "#000";
            context.fillText("Sample Index", width / 2, height - 10); // X-axis label
            context.save();
            context.translate(10, height / 2);
            context.rotate(-Math.PI / 2);
            context.fillText("Variance", 0, 0); // Y-axis label
            context.restore();

            // Plot data
            context.beginPath();
            context.strokeStyle = color;
            data.forEach((value, index) => {
                const x = padding + (index / data.length) * (width - 2 * padding);
                const y = height - padding - value * scale;
                if (index === 0) context.moveTo(x, y);
                else context.lineTo(x, y);
            });
            context.stroke();

            // Draw legend
            context.fillStyle = color;
            context.fillText(label, padding + 10, padding - 10);
        }

        function simulate() {
            const m = parseInt(document.getElementById("numSamples").value);
            const n = parseInt(document.getElementById("sampleSize").value);
            const a = 0, b = 1; // Uniform distribution range

            const correctedVariances = [];
            const uncorrectedVariances = [];

            for (let i = 0; i < m; i++) {
                const sample = generateUniformSample(a, b, n);
                correctedVariances.push(calculateVariance(sample, true));
                uncorrectedVariances.push(calculateVariance(sample, false));
            }

            const correctedMean = correctedVariances.reduce((sum, v) => sum + v, 0) / m;
            const uncorrectedMean = uncorrectedVariances.reduce((sum, v) => sum + v, 0) / m;

            const correctedVarianceMean = correctedVariances.reduce((sum, v) => sum + Math.pow(v - correctedMean, 2), 0) / m;
            const uncorrectedVarianceMean = uncorrectedVariances.reduce((sum, v) => sum + Math.pow(v - uncorrectedMean, 2), 0) / m;

            document.getElementById("results").textContent = `
Corrected Sample Variance:
  Mean: ${correctedMean.toFixed(4)}
  Variance: ${correctedVarianceMean.toFixed(4)}

Uncorrected Sample Variance:
  Mean: ${uncorrectedMean.toFixed(4)}
  Variance: ${uncorrectedVarianceMean.toFixed(4)}

Parent Distribution Variance:
  Theoretical Variance: ${(Math.pow(b - a, 2) / 12).toFixed(4)}
`;

            // Plot corrected and uncorrected variances
            const ctx = document.getElementById("variancePlot").getContext("2d");
            drawPlot(ctx, correctedVariances, "blue", "Corrected Variance");
        }
    </script>
</body>
</html>



