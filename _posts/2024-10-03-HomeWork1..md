---
layout: post
title: "HomeWork 1"
date: 2024-10-03
---

## Research Topics: Theory (T)

- **T1**: What is Statistics?  
- **T2**: What is a Dataset? From the statistical units to the dataset variables and observed values.  
- **T3**: Find and list interesting applications of Statistics in Cybersecurity.  

## Research Topics: Applications (A)

- **A1**: Create simple applications in C# and VB.NET to explore handlers and understand syntax differences between the two languages.

## Research Topics: Theory Relevant to Applications (TA)

- **TA1**: Main differences between C# and VB.NET (handlers, case sensitivity, delimiters, brackets, arrays, generic classes, etc.).

---

## <span style="color:red">Researches about Theory (T)</span>

![statistics](/assets/statistics.jpg)

### 1. Population
- **Definition**: A **population** in statistics refers to the complete set of items, individuals, or observations that share at least one common characteristic. It can include people, objects, events, or data points that are being studied.
  - **Example**: If you're studying the heights of students in a school, the population would be *all* the students in that school.

- **Types of Population**:
  - **Finite population**: Contains a limited number of observations or items.
  - **Infinite population**: Not countable or practically infinite, like all possible outcomes of rolling a die.

- **Census**: When data is collected from *every* member of a population, it's called a **census**.

### 2. Statistical Units (Units of Analysis)
- **Definition**: A **statistical unit** is an individual member or entity of a population that provides a data point for analysis.
  - **Example**: In a study on family income, each family surveyed is a statistical unit.

- **Key Types**:
  - **Individual**: A single person (e.g., students in a school).
  - **Group**: A collection of entities (e.g., households, schools).
  - **Object or Item**: Products, animals, or any other objects being studied.
  - **Event**: Units could also be events like days, transactions, or accidents.

- **Sample**: A **sample** is a subset of the population, consisting of statistical units selected for measurement. It helps generalize findings to the entire population.

### 3. Distribution
- **Definition**: A **distribution** in statistics describes how the values of a variable are spread or arranged.
  - **Example**: The distribution of test scores in a class shows how frequently different scores occur.

- **Key Types of Distributions**:
  - **Probability distribution**: Shows the likelihood of each outcome in a population (e.g., **normal**, **binomial**, **Poisson**).
  - **Frequency distribution**: Summarizes data by showing the number of observations in different ranges.
  - **Empirical distribution**: Derived from actual sample data.

- **Shape of Distributions**:
  - **Normal distribution**: Bell-shaped, symmetric around the mean.
  - **Skewed distribution**: Asymmetric, with a longer tail on one side.
  - **Uniform distribution**: All outcomes are equally likely.

---

## Notion of Average, Floating-Point Representation Errors, and Numerical Solutions

### 1. Notion of Average
- **Definition**: The **average** (or **mean**) is a measure of central tendency that represents the typical value in a dataset.
  - **Formula**: For a set of \( n \) values \( x_1, x_2, \dots, x_n \), the arithmetic mean is given by:
    \[
    \text{Average (mean)} = \frac{1}{n} \sum_{i=1}^{n} x_i
    \]
  - **Types of averages**:
    - **Arithmetic Mean**: The sum of all values divided by the number of values.
    - **Geometric Mean**: The nth root of the product of all values.
    - **Harmonic Mean**: The number of values divided by the sum of the reciprocals of the values.

  - **Example**: For the values \( 3, 4, 8, 10 \), the arithmetic mean is:
    \[
    \frac{3 + 4 + 8 + 10}{4} = 6.25
    \]

### 2. Computational Problems with Floating-Point Representation

#### 2.1. Floating-Point Representation
- **Definition**: Computers use **floating-point** representation to approximate real numbers by expressing them as a **mantissa** (significant digits) and an **exponent**.
  - **Format**: A typical floating-point number is expressed as:
    \[
    x = \text{mantissa} \times 2^{\text{exponent}}
    \]
  - This allows for a wide range of values but introduces **precision limits** because only a finite number of digits are stored.

#### 2.2. Floating-Point Errors

##### 2.2.1. Rounding Errors
- **Definition**: Due to the finite precision of floating-point representation, many real numbers cannot be represented exactly, leading to small **rounding errors**.
  - **Example**: Representing the fraction \( \frac{1}{3} \) as \( 0.333\ldots \), which is truncated, leading to minor errors in subsequent calculations.

##### 2.2.2. Catastrophic Cancellation
- **Definition**: **Catastrophic cancellation** occurs when subtracting two nearly equal numbers, resulting in a significant loss of precision.
  - **Example**: For \( x = 1.0000001 \) and \( y = 1.0000000 \), their difference \( 0.0000001 \) can be reduced to \( 0 \) due to truncation when using limited precision.

- **Impact**: Catastrophic cancellation often arises when subtracting nearly equal numbers, leading to large relative errors in calculations.

### 3. Numerical Solution (Knuth's Approach)

#### 3.1. Knuth's Algorithm for Summation
- **Problem**: Summing large sequences of floating-point numbers can introduce rounding errors, especially when values differ greatly in magnitude.

- **Knuth's Approach**: **Kahan Summation Algorithm** (also called **compensated summation**) reduces the error by keeping a running compensation for lost low-order bits.

  - **Algorithm**:
    1. Initialize `sum = 0` and `c = 0` (compensation for lost lower bits).
    2. For each number \( x_i \):
       - Compute \( y = x_i - c \) (recovers lost low-order bits).
       - Compute \( t = \text{sum} + y \).
       - Update \( c = (t - \text{sum}) - y \).
       - Update \( \text{sum} = t \).
    3. The final `sum` is the corrected total.

  - **Benefit**: Kahan Summation mitigates rounding errors by tracking small error terms and incorporating them into the final result.

- **Example**: Summing \( 1.0 + 1.0 \times 10^{-16} + (-1.0) \) normally could yield \( 0 \), losing the small term. Using Kahan summation, the small term is preserved.

#### 3.2. Knuth's Influence on Numerical Computation
- **Donald Knuth** has been instrumental in addressing numerical stability, emphasizing the importance of using numerically stable algorithms, like Kahan summation, to reduce floating-point errors.

---

[C# src](https://github.com/user0x1234/user0x1234.github.io/tree/main/src/HomeWork1/)
