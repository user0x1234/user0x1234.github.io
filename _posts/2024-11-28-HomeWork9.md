---
layout: post
title: "HomeWork 9"
date: 2024-11-28
markdown: kramdown
---

## Research Topics: Theory (T)

- **T1**: Mention the main properties of the sampling mean and variance.
Illustrate the law of large numbers and some possible applications, especially related to cybersecurity concepts.


- **A1**: Application / practice
Following the same scheme of HMWK 7 compute the distribution of the sampling variance ("corrected" or not).
Determine the distribution of the variances of the samples, and its mean and variance.
discussing the observed relationship with the mean and variance of the parent (theoretical) distribution. 


# <span style="color:red">Researches about Theory (T)</span>


# Sampling Mean and Variance: Key Concepts and Applications

## Main Properties of the Sampling Mean

1. **Unbiasedness**:  
   - The expected value of the sample mean $\( \bar{X} \)$ is equal to the population mean $\( \mu \)$:
     $$
     \mathbb{E}[\bar{X}] = \mu
     $$

2. **Reduced Variability with Larger Samples**:  
   - The variance of the sample mean decreases as the sample size \( n \) increases:
     $$
     \text{Var}(\bar{X}) = \frac{\sigma^2}{n}
     $$
     where $\( \sigma^2 \)$ is the population variance.

3. **Central Limit Theorem (CLT)**:  
   - For large $\( n \)$, the sampling distribution of $\( \bar{X} \)$ approaches a normal distribution, regardless of the population's distribution.

---

## Main Properties of the Sampling Variance

1. **Unbiased Estimator**:  
   - The sample variance $\( s^2 \)$ is an unbiased estimate of the population variance $\( \sigma^2 \)$:
     
     $$
     s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
     $$

2. **Dependence on Sample Size**:  
   - As the sample size $\( n \)$ increases, the sample variance becomes a more stable and accurate estimate of the population variance.

3. **Stochastic Nature**:  
   - While $\( s^2 \)$ estimates $\( \sigma^2 \)$, it varies from sample to sample.

---

## Law of Large Numbers (LLN)

The **Law of Large Numbers (LLN)** ensures that as the sample size $\( n \)$ increases, the sample mean $\( \bar{X} \)$ converges to the population mean $\( \mu \)$. This is formalized as:
$$
\lim_{n \to \infty} \bar{X}_n = \mu
$$

### Key Insights:
- The LLN highlights the reliability of large samples in approximating population parameters.
- Variability in estimates decreases with larger $\( n \)$.

---

## Applications of LLN in Cybersecurity

1. **Anomaly Detection**:  
   - Monitoring login attempts or network packet sizes to detect deviations from the norm.  
   - For instance, analyzing the mean response time for successful logins can reveal potential brute-force attacks.

2. **Risk Assessment**:  
   - Estimating average probabilities of attack vectors based on historical data.  
   - Larger datasets improve accuracy in calculating these probabilities.

3. **Performance Monitoring**:  
   - Assessing average system performance metrics like throughput, downtime, or detection times.  
   - Large samples ensure stable benchmarks for performance evaluation.

4. **Authentication Systems**:  
   - Computing average failure rates in multi-factor authentication systems to identify potential attack patterns.

---

## Practical Example

### Scenario:
- **Dataset**: Response times for detecting phishing attempts.
- **Population Parameters**: Mean $\( \mu = 25 \)$ seconds, variance $\( \sigma^2 = 16 \)$.

### Simulation:
1. Collect samples of size $\( n = 10, 50, 100, 1000 \)$.
2. Compute the sample mean $\( \bar{X} \)$ for each sample.
3. Observe how $\( \bar{X} \)$ approaches $\( \mu = 25 \)$ as $\( n \)$ increases.

### Visualization:
- Plot $\( \bar{X} \)$ against $\( n \)$ to show convergence.
- Highlight reduced variability in sample mean for larger $\( n \)$.

---

## Key Takeaway
The Law of Large Numbers and properties of sampling mean and variance are foundational in cybersecurity. They allow for robust predictions, anomaly detection, and system performance evaluations, ensuring more reliable and secure operations in the face of uncertainty.


# <span style="color:red">Researches about Application (A)</span>

# Sampling Variance Analysis

## Objective:
1. Compute the distribution of the sampling variance (corrected and uncorrected).
2. Determine:
   - The mean and variance of the sampling variances.
3. Compare the results with the population (theoretical) variance $\( \sigma^2 \)$ and discuss observed relationships.

---

## Theoretical Background:

### Population Variance:
The variance of a population is defined as:
$$
\sigma^2 = \mathbb{E}[(X - \mu)^2]
$$

### Sample Variance:
The sample variance can be computed using two formulas:
1. **Uncorrected Sample Variance**:
   $$
   s_u^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2
   $$
   This underestimates the population variance for finite \( n \).

2. **Corrected Sample Variance** (Bessel's correction):
   $$
   s_c^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
   $$
   The cor$rection makes $\( s_c^2 \)$ an unbiased estimator of $\( \sigma^2 \)$.

---

## Sampling Variance Distribution:
The sampling variance follows a scaled chi-squared distribution:
$$
(n-1)s_c^2 \sim \sigma^2 \chi^2_{n-1}
$$
This means:
- The mean of $\( s_c^2 \)$ equals the population variance:
  $$
  \mathbb{E}[s_c^2] = \sigma^2
  $$
- The variance of $\( s_c^2 \)$ depends on $\( n \)$:
  $$
  \text{Var}(s_c^2) = \frac{2\sigma^4}{n-1}
  $$

---

## Practical Implementation:

### Steps:
1. Generate a large number $\( m \)$ of samples, each of size $\( n \)$, from a given parent distribution.
2. For each sample, compute:
   - The corrected sample variance $\( s_c^2 \)$.
   - The uncorrected sample variance $\( s_u^2 \)$.
3. Collect the variances across samples and plot their distributions.
4. Compute:
   - The mean and variance of the distributions of $\( s_c^2 \)$ and $\( s_u^2 \)$.
5. Compare these results with the theoretical variance $\( \sigma^2 \)$ of the parent distribution.

### Observations:
1. The mean of $\( s_c^2 \)$ should converge to $\( \sigma^2 \)$.
2. The variance of $\( s_c^2 \)$ should decrease as $\( n \)$ increases.
3. The uncorrected variance $\( s_u^2 \)$ is biased and underestimates $\( \sigma^2 \)$.

---

## Example Implementation:

### **Simulation Parameters**:
- Parent distribution: Normal ($\( \mu = 0, \sigma^2 = 1 \)$).
- Number of samples ($\( m \)$): 1000.
- Sample sizes (\( n \)): 10, 30, 50, 100.

### **Simulation Results**:
1. **Distributions**:
   - Plot histograms of $\( s_c^2 \)$ and $\( s_u^2 \)$ for each $\( n \)$.
2. **Summary Statistics**:
   - Compare the theoretical variance $\( \sigma^2 \)$ with the mean of $\( s_c^2 \)$ and $\( s_u^2 \)$.
   - Analyze the variance of $\( s_c^2 \)$ and compare with $\( \frac{2\sigma^4}{n-1} \)$.

---

## Code Example (in JavaScript):

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta$ name="viewpor$t" content="width=device-width, initial-scale=1.0">
    <title>Sampling Variance Simulation</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>$
    <h1>Sa$mpling Variance Simu$lation</h1>
    <div$>
        <canvas id=$"varianceCh$art" width="800" hei$ght="40$0"></canvas>
    </div>
    <script>
   $     const $numSamples = 1000;  // Number $of samples
        const$ sampleSizes = [10, 30, 50, 100];  // Different sample sizes
        const populationMean = 0;  // Mean of the parent distribution
        const populationVariance = 1;  // Variance of the parent distribution

        // Function to generate random samples from a normal distribution
        function generateNormalSample(mean, variance, size) {
            return Array.from({ length: size }, () => {
                return mean + Math$.sqrt(variance) * Math.rand$om();
            });
  $      }$

        // Function to calculate corrected sample variance
        function correctedVariance(sample) {
            const mean = sample.reduce((a, b) => a + b, 0) / sample.length;
     $       retu$rn sa$mple.reduce$((sum, x) $=> sum $+ Math.pow(x - mean, 2), 0) / (sampl$e.length - 1);$
        }

      $  // Main s$imula$tion
        const results = sampleSizes.map(size => {
            const variances = [];
            for (let i = 0; i < numSamples; i++) {
                const sample = generateNormalSample(populationMean, populationVariance, size);
                variances.push(correctedVariance(sample));
            }
            return { size, variances };
        });

        // Chart.js visualization
        const ctx = document.getElementById('varianceChart').getContext('2d');
        const datasets = results.map((result, index) => ({
            label: `n = ${result.size}`,
            data: result.variances,
            borderColor: `hsl(${(index / results.length) * 360}, 70%, 50%)`,
            fill: false
        }));

        new Chart(ctx, {
            type: 'line',
            data: {
                labels: Array.from({ length: numSamples }, (_, i) => i + 1),
                datasets: datasets
            },
            options: {
                scales: {
                    x: { title: { display: true, text: 'Sample Index' } },
                    y: { title: { display: true, text: 'Sample Variance' } }
                },
                responsive: true
            }
        });
    </script>
</body>
</html>
