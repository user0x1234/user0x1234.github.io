---
layout: post
title: "HomeWork 2"
date: 2024-10-10
markdown: kramdown
---

## Research Topics: Theory (T)

- **T1**: Find the simplest and most elegant way to show the Welford recursion.
(Winner will have prize ðŸ˜Š )



## Research Topics: Applications (A)

- **A1**: Refine you Eulerâ€“Maruyama simulator to approximate numerical solution of a stochastic 
differential equation (SDE), buy adding the following variants to the existing framework:

A. Jumps -1 +1 with prob. p [random walk]
B. Absolute and relative frequency trajectories
C. Final distribution and intermediate distributions (at one internal
time/step selectable from the gui), with mean and variance.

(make it all parametric so that one unique interface will handle it all)

Research
1.  Find the simplest and most elegant way to show the Welford recursion.
(Winner will have prize ðŸ˜Š )

Application
2. Refine you Eulerâ€“Maruyama simulator to approximate numerical solution of a stochastic 
differential equation (SDE), buy adding the following variants to the existing framework:

A. Jumps -1 +1 with prob. p [random walk]
B. Absolute and relative frequency trajectories
C. Final distribution and intermediate distributions (at one internal
time/step selectable from the gui), with mean and variance.

(make it all parametric so that one unique interface will handle it all)

Research
Make your personal notes about the behavior of mean and variance wrt to time.
What did you observe in all the 4 different cases (relative/abs freq & Bernoulli/random walk) ?

# <span style="color:red">Researches about Theory (T)</span>

# (T1) Find the simplest and most elegant way to show the Welford recursion

## Welford's Algorithm for Mean and Variance

Welfordâ€™s algorithm provides an efficient way to compute the **mean** and **variance** in a single pass over the data, without the need to store all data points. This is particularly useful for large datasets or streaming data.

## Recursive Formulation

Let:
- \( x_1, x_2, \dots, x_n \) be the data points.
- \( \mu_n \) be the mean after observing \( n \) data points.
- \( \sigma^2_n \) be the variance after observing \( n \) data points.

### 1. Mean Recursion

The mean \( \mu_n \) after \( n \) data points is updated as:

\[
\mu_n = \mu_{n-1} + \frac{(x_n - \mu_{n-1})}{n}
\]

Where:
- \( \mu_{n-1} \) is the mean after \( n-1 \) data points.
- \( x_n \) is the new data point.

### 2. Variance Recursion

The variance \( \sigma^2_n \) can be updated using the intermediate sum of squares of differences from the mean:

\[
M_n = M_{n-1} + (x_n - \mu_{n-1})(x_n - \mu_n)
\]

Finally, the variance \( \sigma^2_n \) is calculated as:

\[
\sigma^2_n = \frac{M_n}{n}
\]

### Algorithm Steps

1. **Initialization**:
   - Set initial values: 
     \[
     \mu_0 = 0, \quad M_0 = 0
     \]
   
2. **For each new data point \( x_n \)**:
   - Update the mean using:
     \[
     \mu_n = \mu_{n-1} + \frac{(x_n - \mu_{n-1})}{n}
     \]
   - Update the intermediate sum \( M_n \) using:
     \[
     M_n = M_{n-1} + (x_n - \mu_{n-1})(x_n - \mu_n)
     \]
   - Compute the variance using:
     \[
     \sigma^2_n = \frac{M_n}{n}
     \]

### Benefits of Welfordâ€™s Algorithm

- **Single-pass**: The algorithm computes the mean and variance in a single pass through the data, making it memory-efficient.
- **Numerical stability**: It avoids the precision issues associated with calculating variance using the naive two-pass approach.

This recursive method efficiently computes the mean and variance in real-time without requiring all data points to be stored in memory.



## <span style="color:red">Researches about Applications (A)</span>


[JS src](https://github.com/user0x1234/user0x1234.github.io/tree/main/src/hw2/js/)

[C# src](https://github.com/user0x1234/user0x1234.github.io/tree/main/src/hw2/c#/)


